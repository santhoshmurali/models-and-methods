{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn \n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only one feature\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bos = pd.DataFrame(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos.columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos['PRICE'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = bos.drop('PRICE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Liner Regression Object\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X, bos.PRICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.4911032804\n"
     ]
    }
   ],
   "source": [
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 30.00821269  25.0298606   30.5702317   28.60814055  27.94288232\n  25.25940048  23.00433994  19.5347558   11.51696539  18.91981483\n  18.9958266   21.58970854  20.90534851  19.55535931  19.2837957\n  19.30000174  20.52889993  16.9096749   16.17067411  18.40781636\n  12.52040454  17.67104565  15.82934891  13.80368317  15.67708138\n  13.3791645   15.46258829  14.69863607  19.54518512  20.87309945\n  11.44806825  18.05900412   8.78841666  14.27882319  13.69097132\n  23.81755469  22.34216285  23.11123204  22.91494157  31.35826216\n  34.21485385  28.0207132   25.20646572  24.61192851  22.94438953\n  22.10150945  20.42467417  18.03614022   9.10176198  17.20856571\n  21.28259372  23.97621248  27.65853521  24.0521088   15.35989132\n  31.14817003  24.85878746  33.11017111  21.77458036  21.08526739\n  17.87203538  18.50881381  23.9879809   22.54944098  23.37068403\n  30.36557584  25.53407332  21.11758504  17.42468223  20.7893086\n  25.20349174  21.74490595  24.56275612  24.04479519  25.5091157\n  23.97076758  22.94823519  23.36106095  21.26432549  22.4345376\n  28.40699937  26.99734716  26.03807246  25.06152125  24.7858613\n  27.79291889  22.16927073  25.89685664  30.67771522  30.83225886\n  27.12127354  27.41597825  28.9456478   29.08668003  27.04501726\n  28.62506705  24.73038218  35.78062378  35.11269515  32.25115468\n  24.57946786  25.59386215  19.76439137  20.31157117  21.4353635\n  18.53971968  17.18572611  20.74934949  22.64791346  19.77000977\n  20.64745349  26.52652691  20.77440554  20.71546432  25.17461484\n  20.4273652   23.37862521  23.69454145  20.33202239  20.79378139\n  21.92024414  22.47432006  20.55884635  16.36300764  20.56342111\n  22.48570454  14.61264839  15.1802607   18.93828443  14.0574955\n  20.03651959  19.41306288  20.06401034  15.76005772  13.24771577\n  17.26167729  15.87759672  19.36145104  13.81270814  16.44782934\n  13.56511101   3.98343974  14.59241207  12.14503093   8.72407108\n  12.00815659  15.80308586   8.50963929   9.70965512  14.79848067\n  20.83598096  18.30017013  20.12575267  17.27585681  22.35997992\n  20.07985184  13.59903744  33.26635221  29.03938379  25.56694529\n  32.71732164  36.78111388  40.56615533  41.85122271  24.79875684\n  25.3771545   37.20662185  23.08244608  26.40326834  26.65647433\n  22.55412919  24.2970948   22.98024802  29.07488389  26.52620066\n  30.72351225  25.61835359  29.14203283  31.43690634  32.9232938\n  34.72096487  27.76792733  33.88992899  30.99725805  22.72124288\n  24.76567683  35.88131719  33.42696242  32.41513625  34.51611818\n  30.76057666  30.29169893  32.92040221  32.11459912  31.56133385\n  40.84274603  36.13046343  32.66639271  34.70558647  30.09276228\n  30.64139724  29.29189704  37.07062623  42.02879611  43.18582722\n  22.6923888   23.68420569  17.85435295  23.49543857  17.00872418\n  22.39535066  17.06152243  22.74106824  25.21974252  11.10601161\n  24.51300617  26.60749026  28.35802444  24.91860458  29.69254951\n  33.18492755  23.77145523  32.14086508  29.74802362  38.36605632\n  39.80716458  37.58362546  32.39769704  35.45048257  31.23446481\n  24.48478321  33.28615723  38.04368164  37.15737267  31.71297469\n  25.26658017  30.101515    32.71897655  28.42735376  28.42999168\n  27.2913215   23.74446671  24.11878941  27.40241209  16.32993575\n  13.39695213  20.01655581  19.86205904  21.28604604  24.07796482\n  24.20603792  25.04201534  24.91709097  29.93762975  23.97709054\n  21.69931969  37.51051381  43.29459357  36.48121427  34.99129701\n  34.80865729  37.16296374  40.9823638   34.44211691  35.83178068\n  28.24913647  31.22022312  40.83256202  39.31768808  25.71099424\n  22.30344878  27.20551341  28.51386352  35.47494122  36.11110647\n  33.80004807  35.61141951  34.84311742  30.35359323  35.31260262\n  38.79684808  34.33296541  40.34038636  44.67339923  31.5955473\n  27.35994642  20.09520596  27.04518524  27.21674397  26.91105226\n  33.43602979  34.40228785  31.83374181  25.82416035  24.43687139\n  28.46348891  27.36916176  19.54441878  29.11480679  31.90852699\n  30.77325183  28.9430835   28.88108106  32.79876794  33.20356949\n  30.76568546  35.55843485  32.70725436  28.64759861  23.59388439\n  18.5461558   26.88429024  23.28485442  25.55002201  25.48337323\n  20.54343769  17.61406384  18.37627933  24.29187594  21.3257202\n  24.88826131  24.87143049  22.87255605  19.4540234   25.11948741\n  24.66816374  23.68209656  19.33951725  21.17636041  24.25306588\n  21.59311197  19.98766667  23.34079584  22.13973959  21.55349196\n  20.61808868  20.1607571   19.28455466  22.16593919  21.24893735\n  21.42985456  30.32874523  22.04915396  27.70610125  28.54595004\n  16.54657063  14.78278261  25.27336772  27.54088054  22.14633467\n  20.46081206  20.54472332  16.88194391  25.40066956  14.32299547\n  16.5927403   19.63224597  22.7117302   22.19946949  19.1989151\n  22.66091019  18.92059374  18.22715359  20.22444386  37.47946099\n  14.29172583  15.53697148  10.82825817  23.81134987  32.64787163\n  34.61163401  24.94604102  26.00259724   6.12085728   0.78021126\n  25.311373    17.73465914  20.22593282  15.83834861  16.83742401\n  14.43123608  18.47647773  13.42427933  13.05677824   3.27646485\n   8.05936467   6.13903114   5.62271213   6.44935154  14.20597451\n  17.21022671  17.29035065   9.89064351  20.21972222  17.94511052\n  20.30017588  19.28790318  16.33300008   6.56843662  10.87541577\n  11.88704097  17.81098929  18.25461066  12.99282707   7.39319053\n   8.25609561   8.07899971  19.98563715  13.69651744  19.83511412\n  15.2345378   16.93112419   1.69347406  11.81116263  -4.28300934\n   9.55007844  13.32635521   6.88351077   6.16827417  14.56933235\n  19.59292932  18.1151686   18.52011987  13.13707457  14.59662601\n   9.8923749   16.31998048  14.06750301  14.22573568  13.00752251\n  18.13277547  18.66645496  21.50283795  17.00039379  15.93926602\n  13.32952716  14.48949211   8.78366731   4.8300317   13.06115528\n  12.71101472  17.2887624   18.73424906  18.05271013  11.49855612\n  13.00841512  17.66975577  18.12342294  17.51503231  17.21307203\n  16.48238543  19.40079737  18.57392951  22.47833186  15.24179836\n  15.78327609  12.64853778  12.84121049  17.17173661  18.50906858\n  19.02803874  20.16441773  19.76975335  22.42614937  20.31750314\n  17.87618837  14.3391341   16.93715603  16.98716629  18.59431701\n  20.16395155  22.97743546  22.45110639  25.5707207   16.39091112\n  16.09765427  20.52835689  11.5429045   19.20387482  21.86820603\n  23.47052203  27.10034494  28.57064813  21.0839881   19.4490529\n  22.2189221   19.65423066  21.324671    11.86231364   8.22260592\n   3.65825168  13.76275951  15.93780944  20.62730097  20.61035443\n  16.88048035  14.01017244  19.10825534  21.29720741  18.45524217\n  20.46764235  23.53261729  22.37869798  27.62934247  26.12983844\n  22.34870269].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-21de4e9d228f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPRICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Home\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    388\u001b[0m                         multioutput='variance_weighted')\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Home\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Home\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    241\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32mC:\\Home\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 30.00821269  25.0298606   30.5702317   28.60814055  27.94288232\n  25.25940048  23.00433994  19.5347558   11.51696539  18.91981483\n  18.9958266   21.58970854  20.90534851  19.55535931  19.2837957\n  19.30000174  20.52889993  16.9096749   16.17067411  18.40781636\n  12.52040454  17.67104565  15.82934891  13.80368317  15.67708138\n  13.3791645   15.46258829  14.69863607  19.54518512  20.87309945\n  11.44806825  18.05900412   8.78841666  14.27882319  13.69097132\n  23.81755469  22.34216285  23.11123204  22.91494157  31.35826216\n  34.21485385  28.0207132   25.20646572  24.61192851  22.94438953\n  22.10150945  20.42467417  18.03614022   9.10176198  17.20856571\n  21.28259372  23.97621248  27.65853521  24.0521088   15.35989132\n  31.14817003  24.85878746  33.11017111  21.77458036  21.08526739\n  17.87203538  18.50881381  23.9879809   22.54944098  23.37068403\n  30.36557584  25.53407332  21.11758504  17.42468223  20.7893086\n  25.20349174  21.74490595  24.56275612  24.04479519  25.5091157\n  23.97076758  22.94823519  23.36106095  21.26432549  22.4345376\n  28.40699937  26.99734716  26.03807246  25.06152125  24.7858613\n  27.79291889  22.16927073  25.89685664  30.67771522  30.83225886\n  27.12127354  27.41597825  28.9456478   29.08668003  27.04501726\n  28.62506705  24.73038218  35.78062378  35.11269515  32.25115468\n  24.57946786  25.59386215  19.76439137  20.31157117  21.4353635\n  18.53971968  17.18572611  20.74934949  22.64791346  19.77000977\n  20.64745349  26.52652691  20.77440554  20.71546432  25.17461484\n  20.4273652   23.37862521  23.69454145  20.33202239  20.79378139\n  21.92024414  22.47432006  20.55884635  16.36300764  20.56342111\n  22.48570454  14.61264839  15.1802607   18.93828443  14.0574955\n  20.03651959  19.41306288  20.06401034  15.76005772  13.24771577\n  17.26167729  15.87759672  19.36145104  13.81270814  16.44782934\n  13.56511101   3.98343974  14.59241207  12.14503093   8.72407108\n  12.00815659  15.80308586   8.50963929   9.70965512  14.79848067\n  20.83598096  18.30017013  20.12575267  17.27585681  22.35997992\n  20.07985184  13.59903744  33.26635221  29.03938379  25.56694529\n  32.71732164  36.78111388  40.56615533  41.85122271  24.79875684\n  25.3771545   37.20662185  23.08244608  26.40326834  26.65647433\n  22.55412919  24.2970948   22.98024802  29.07488389  26.52620066\n  30.72351225  25.61835359  29.14203283  31.43690634  32.9232938\n  34.72096487  27.76792733  33.88992899  30.99725805  22.72124288\n  24.76567683  35.88131719  33.42696242  32.41513625  34.51611818\n  30.76057666  30.29169893  32.92040221  32.11459912  31.56133385\n  40.84274603  36.13046343  32.66639271  34.70558647  30.09276228\n  30.64139724  29.29189704  37.07062623  42.02879611  43.18582722\n  22.6923888   23.68420569  17.85435295  23.49543857  17.00872418\n  22.39535066  17.06152243  22.74106824  25.21974252  11.10601161\n  24.51300617  26.60749026  28.35802444  24.91860458  29.69254951\n  33.18492755  23.77145523  32.14086508  29.74802362  38.36605632\n  39.80716458  37.58362546  32.39769704  35.45048257  31.23446481\n  24.48478321  33.28615723  38.04368164  37.15737267  31.71297469\n  25.26658017  30.101515    32.71897655  28.42735376  28.42999168\n  27.2913215   23.74446671  24.11878941  27.40241209  16.32993575\n  13.39695213  20.01655581  19.86205904  21.28604604  24.07796482\n  24.20603792  25.04201534  24.91709097  29.93762975  23.97709054\n  21.69931969  37.51051381  43.29459357  36.48121427  34.99129701\n  34.80865729  37.16296374  40.9823638   34.44211691  35.83178068\n  28.24913647  31.22022312  40.83256202  39.31768808  25.71099424\n  22.30344878  27.20551341  28.51386352  35.47494122  36.11110647\n  33.80004807  35.61141951  34.84311742  30.35359323  35.31260262\n  38.79684808  34.33296541  40.34038636  44.67339923  31.5955473\n  27.35994642  20.09520596  27.04518524  27.21674397  26.91105226\n  33.43602979  34.40228785  31.83374181  25.82416035  24.43687139\n  28.46348891  27.36916176  19.54441878  29.11480679  31.90852699\n  30.77325183  28.9430835   28.88108106  32.79876794  33.20356949\n  30.76568546  35.55843485  32.70725436  28.64759861  23.59388439\n  18.5461558   26.88429024  23.28485442  25.55002201  25.48337323\n  20.54343769  17.61406384  18.37627933  24.29187594  21.3257202\n  24.88826131  24.87143049  22.87255605  19.4540234   25.11948741\n  24.66816374  23.68209656  19.33951725  21.17636041  24.25306588\n  21.59311197  19.98766667  23.34079584  22.13973959  21.55349196\n  20.61808868  20.1607571   19.28455466  22.16593919  21.24893735\n  21.42985456  30.32874523  22.04915396  27.70610125  28.54595004\n  16.54657063  14.78278261  25.27336772  27.54088054  22.14633467\n  20.46081206  20.54472332  16.88194391  25.40066956  14.32299547\n  16.5927403   19.63224597  22.7117302   22.19946949  19.1989151\n  22.66091019  18.92059374  18.22715359  20.22444386  37.47946099\n  14.29172583  15.53697148  10.82825817  23.81134987  32.64787163\n  34.61163401  24.94604102  26.00259724   6.12085728   0.78021126\n  25.311373    17.73465914  20.22593282  15.83834861  16.83742401\n  14.43123608  18.47647773  13.42427933  13.05677824   3.27646485\n   8.05936467   6.13903114   5.62271213   6.44935154  14.20597451\n  17.21022671  17.29035065   9.89064351  20.21972222  17.94511052\n  20.30017588  19.28790318  16.33300008   6.56843662  10.87541577\n  11.88704097  17.81098929  18.25461066  12.99282707   7.39319053\n   8.25609561   8.07899971  19.98563715  13.69651744  19.83511412\n  15.2345378   16.93112419   1.69347406  11.81116263  -4.28300934\n   9.55007844  13.32635521   6.88351077   6.16827417  14.56933235\n  19.59292932  18.1151686   18.52011987  13.13707457  14.59662601\n   9.8923749   16.31998048  14.06750301  14.22573568  13.00752251\n  18.13277547  18.66645496  21.50283795  17.00039379  15.93926602\n  13.32952716  14.48949211   8.78366731   4.8300317   13.06115528\n  12.71101472  17.2887624   18.73424906  18.05271013  11.49855612\n  13.00841512  17.66975577  18.12342294  17.51503231  17.21307203\n  16.48238543  19.40079737  18.57392951  22.47833186  15.24179836\n  15.78327609  12.64853778  12.84121049  17.17173661  18.50906858\n  19.02803874  20.16441773  19.76975335  22.42614937  20.31750314\n  17.87618837  14.3391341   16.93715603  16.98716629  18.59431701\n  20.16395155  22.97743546  22.45110639  25.5707207   16.39091112\n  16.09765427  20.52835689  11.5429045   19.20387482  21.86820603\n  23.47052203  27.10034494  28.57064813  21.0839881   19.4490529\n  22.2189221   19.65423066  21.324671    11.86231364   8.22260592\n   3.65825168  13.76275951  15.93780944  20.62730097  20.61035443\n  16.88048035  14.01017244  19.10825534  21.29720741  18.45524217\n  20.46764235  23.53261729  22.37869798  27.62934247  26.12983844\n  22.34870269].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
