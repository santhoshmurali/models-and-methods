---
title: "Data Mining Assignment"
author: "Group1"
date: "July 23, 2017"
output:
  word_document: default
  pdf_document: default
---
# Author : Santhosh, Krishn
# Date : 17-Jul-2017

# a) Data Import (Target variable is "Attrition" column)
# b) Split the data in Dev & Hold Out sample (70:30)
# c) Perform Exploratory Data Analysis
# d) Identify columns which are of no use. drop those columns
# e) Write Hypothesis and validate the Hypothesis
# f) Build Neural Network Model (Development sample)
# g) Validate NN model on Hold Out. If need be improvize
# h) Build Random Forest Model
# i) Validate RF Model
# j) Compare NN with RF
# k) Combine NN and RF into Ensemble Model
# l) Check whether Ensemble Model Performance outperforms the individual RF & NN model
```{r}
library(scales)
library(RColorBrewer)
library(neuralnet)
library(googleVis)
library(data.table)
library(caret)
library(ROCR)
library(randomForest)
library(ineq)


getwd()
setwd("C:/Home/Work/GreatLakes/Data Mining/Assignments/NeuralNet and RF")
darkCol = brewer.pal(9, "Set1")

HRSourceData = read.table("C:/Home/Work/GreatLakes/Data Mining/Assignments/NeuralNet and RF/1452762979_586__HR_Employee_Attrition_Data.csv", header = T, sep=",")



#Data Preparation
# Target data is a factor of String, converting it to Integer of 0 or 1
Target_Attrition = as.vector(HRSourceData$Attrition)
Target_Attrition = replace(Target_Attrition,Target_Attrition=="No",0)
Target_Attrition = replace(Target_Attrition,Target_Attrition=="Yes",1)
Target_Attrition = as.integer(Target_Attrition)
HRSourceData$TargetAttrition = Target_Attrition

#plot(gvisTable(HRSourceData))
names(HRSourceData)
str(HRSourceData)
#List of Numerical Variable
# Age : COnt
# DailyRate : Ratio
# Distance from Home : Ratio
# Education : Ordinal
# Employee Count : Discrete
# Employee Number : Nominal
# Employee Satisfaction : Ordinal
# Hourly Rate : Cont, Ratio
# Job Involvement : Discrete
# Job Level : Ordinal
# Job Satisfaction : Ordinal
# Monthly Income : Ratio, Cont
# Monthly Rate : Ration, cont
# Num Company Worked : Discrete
# Percent Salaray Hike : Interval, Cont
# Performance Rating : Ordinal
# Relationship Satisfaction : Ordinal
# Standard Hours : Cont
# Stock Option Level : Ordinal
# Total Working Years : Discrete
# Training Times Last Year : Discrete
# Work Life Balance : Ordinal
# Years at Company : Cont, Interval
# Years in Current Role : Cont, Interval
# Years Since Last Promotion : Cont, Interval
# Years with Current Manager : Cont, Interval

#List of Categorical Variable
#BusinessTravel
#Department
#EducationField
#Gender
#JobRole
#MaritalStatus
#Over18
#OverTime

#Business Travel
plot(HRSourceData$BusinessTravel, col=darkCol, main = "Travel Details")
BusinessTravel = data.frame(summary(HRSourceData$BusinessTravel))
round((BusinessTravel/sum(BusinessTravel))*100,2)

#Department
plot(HRSourceData$Department, col=darkCol, main="Department")
vDepartment = data.frame(summary(HRSourceData$Department))
round((vDepartment/sum(vDepartment))*100,2)

#EducationField
plot(HRSourceData$EducationField, col=darkCol, main="Eduction Field")
vEducationField = data.frame(summary(HRSourceData$EducationField))
round((vEducationField/sum(vEducationField))*100,2)

#Gender
plot(HRSourceData$Gender, col=darkCol,main="Gender")
vGender = data.frame(summary(HRSourceData$Gender))
round((vGender/sum(vGender))*100,2)

#JobRole
plot(HRSourceData$JobRole, col=darkCol, main="Job Role")
vJobRole = data.frame(summary(HRSourceData$JobRole))
round((vJobRole/sum(vJobRole))*100,2)

#MaritalStatus
plot(HRSourceData$MaritalStatus, col=darkCol, main="Marital Status")
vMaritalStatus = data.frame(summary(HRSourceData$MaritalStatus))
round((vMaritalStatus/sum(vMaritalStatus))*100,2)

#OverTime
plot(HRSourceData$OverTime, col=darkCol, main="Over time")
vOverTime = data.frame(summary(HRSourceData$OverTime))
round((vOverTime/sum(vOverTime))*100,2)

#Finding Ouliers in Cont data
x =  subset(HRSourceData, 
            select = c("Age",
                       "DailyRate",
                       "DistanceFromHome",
                       "Education",
                       "EmployeeCount",
                       "EmployeeNumber",
                       "EnvironmentSatisfaction",
                       "HourlyRate",
                       "JobInvolvement",
                       "JobLevel",
                       "JobSatisfaction",
                       "MonthlyIncome",
                       "MonthlyRate",
                       "NumCompaniesWorked",
                       "PercentSalaryHike",
                       "PerformanceRating",
                       "RelationshipSatisfaction",
                       "StandardHours",
                       "StockOptionLevel",
                       "TotalWorkingYears",
                       "TrainingTimesLastYear",
                       "WorkLifeBalance",
                       "YearsAtCompany",
                       "YearsInCurrentRole",
                       "YearsSinceLastPromotion",
                       "YearsWithCurrManager"))
class(x)
y = scale(x[,])
boxplot(y, col=darkCol, main="Numerical Variables")


#Before splitting the data as development and holdout, let us convert the categorical variables to continous variables.
# Get rid of variables that are of no use
# StandardHours and Over18 are having same values for all observations, so we can remove those variables.
CleanedHRData = HRSourceData[,!(names(HRSourceData) %in% c("EmployeeCount", "StandardHours","Over18","EmployeeNumber"))]

# Converting Categorical Variables to COnt
#BusinessTravel
mBusinessTravel = model.matrix(~ BusinessTravel - 1, data = CleanedHRData)
head(mBusinessTravel)
CleanedHRData = data.frame(CleanedHRData, mBusinessTravel)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("BusinessTravel"))]

#Department
mDepartment = model.matrix(~ Department - 1, data = CleanedHRData)
head(mDepartment)
CleanedHRData = data.frame(CleanedHRData, mDepartment)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("Department"))]

#EducationField
mEducationField = model.matrix(~ EducationField - 1, data = CleanedHRData)
head(mEducationField)
CleanedHRData = data.frame(CleanedHRData, mEducationField)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("EducationField"))]

#Gender
mGender = model.matrix(~ Gender - 1, data = CleanedHRData)
head(mGender)
CleanedHRData = data.frame(CleanedHRData, mGender)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("Gender"))]

#JobRole
mJobRole = model.matrix(~ JobRole - 1, data = CleanedHRData)
head(mJobRole)
CleanedHRData = data.frame(CleanedHRData, mJobRole)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("JobRole"))]

#MaritalStatus
mMaritalStatus = model.matrix(~ MaritalStatus - 1, data = CleanedHRData)
head(mMaritalStatus)
CleanedHRData = data.frame(CleanedHRData, mMaritalStatus)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("MaritalStatus"))]

#OverTime
mOverTime = model.matrix(~ OverTime - 1, data = CleanedHRData)
head(mOverTime)
CleanedHRData = data.frame(CleanedHRData, mOverTime)
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("OverTime"))]

CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("Attrition"))]
CleanedHRData = cbind(CleanedHRData[,(names(CleanedHRData) %in% c("TargetAttrition"))],
                      CleanedHRData[,!(names(CleanedHRData) %in% c("TargetAttrition"))])
names(CleanedHRData)[1] = "TargetAttrition"




str(CleanedHRData)

#Test for Significance using Anova
fit1 = aov(TargetAttrition ~ ., data = CleanedHRData)
summary(fit1)

#Following Variables came out as insignificant, it can be dropped from the data set.
#                                   Df Sum Sq Mean Sq F value   Pr(>F)
#Education                           1   0.00   0.000   0.004 0.952001    
#HourlyRate                          1   0.03   0.033   0.320 0.571858    
#MonthlyIncome                       1   0.02   0.024   0.237 0.626222    
#MonthlyRate                         1   0.17   0.172   1.671 0.196237    
#PercentSalaryHike                   1   0.20   0.199   1.931 0.164728    
#PerformanceRating                   1   0.10   0.104   1.015 0.313771    
#YearsAtCompany                      1   0.03   0.030   0.295 0.586925    
#JobRoleHuman.Resources              1   0.03   0.026   0.252 0.615773    
#JobRoleManager                      1   0.01   0.006   0.060 0.806153    
#MaritalStatusDivorced               1   0.11   0.110   1.065 0.302052  
CleanedHRData = CleanedHRData[,!(names(CleanedHRData) %in% c("Education","HourlyRate",
                                                             "MonthlyIncome","MonthlyRate",
                                                             "PercentSalaryHike", "PerformanceRating",
                                                             "YearsAtCompany","JobRoleHuman.Resources",
                                                             "JobRoleManager", "MaritalStatusDivorced"))]
fit2 = aov(TargetAttrition ~ ., data = CleanedHRData)
summary(fit2)

 
```


#Attrition Propotion
PopulationPropotion = sum(CleanedHRData$TargetAttrition)/nrow(CleanedHRData)
percent(PopulationPropotion)

#Common for both NN and RF
#Sampling
sampleIndex = sample(nrow(CleanedHRData), nrow(CleanedHRData)*.7)
#Splitting of Data
#Training Data
HrDev = CleanedHRData[sampleIndex,]
#Testing Data
HrHoldOut = CleanedHRData[-sampleIndex,]



#Exloratory Data analysis (c)
#Data Count on Development and HOld Out
#Development Sample
dim(HrDev)

#Holdout Sample
dim(HrHoldOut)

#Propotions comparison
#Propotion in Dev
DevPropotion = sum(HrDev$TargetAttrition)/(nrow(HrDev))
DevPropotion

#Propotion in Holdout
HOPropotion = sum(HrHoldOut$TargetAttrition)/(nrow(HrDev))
HOPropotion

PopulationPropotion

rbind(PopulationPropotion,DevPropotion, HOPropotion) # Comparison of the Distribution of Data.

# Building Neural Network Model
# For Building the Neural net, we have to be keen in selecting following parameters
# number hidden layers
# Number of neuron (tumbrule is sqrt)
# epoh
# Activation Function
# avoiding overfitting.
# function for dealing with error 
# threshold - important factor that decides over fitting.
# stopmax
# learning rate
names(CleanedHRData)
nn1 = neuralnet(TargetAttrition ~ Age + DailyRate + DistanceFromHome + EnvironmentSatisfaction + JobInvolvement + JobLevel + JobSatisfaction + NumCompaniesWorked + RelationshipSatisfaction + StockOptionLevel + TotalWorkingYears +  TrainingTimesLastYear + WorkLifeBalance + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager + BusinessTravelNon.Travel + BusinessTravelTravel_Frequently + BusinessTravelTravel_Rarely + GenderFemale + GenderMale + JobRoleHealthcare.Representative + JobRoleLaboratory.Technician + JobRoleManufacturing.Director + JobRoleResearch.Director + JobRoleResearch.Scientist + JobRoleSales.Executive + JobRoleSales.Representative + MaritalStatusMarried + MaritalStatusSingle + OverTimeNo + OverTimeYes ,
                data = HrDev,
                hidden = c(3,2),
              linear.output = FALSE,
                err.fct = "sse",
                lifesign = "full",
                lifesign.step = 10,
                threshold = 0.01,
                stepmax = 4000)


plot(nn1)


nn1$net.result[[1]]
HrDev$Prob = as.numeric(nn1$net.result[[1]])
hist(HrDev$Prob)

#Cleaning the Extreme Values
TargetAttrition = HrDev[,1]
TargetAttrition
HRDevScaledData =  scale(HrDev[,-1])
HRDevScaledData = cbind(TargetAttrition,HRDevScaledData )
#plot(gvisTable(data.frame(HRDevScaledData)))

#Distribution is not Proper, so, let us scale the data
nn2 = neuralnet(TargetAttrition ~ Age + DailyRate + DistanceFromHome + EnvironmentSatisfaction + JobInvolvement + JobLevel + JobSatisfaction + NumCompaniesWorked + RelationshipSatisfaction + StockOptionLevel + TotalWorkingYears +  TrainingTimesLastYear + WorkLifeBalance + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager + BusinessTravelNon.Travel + BusinessTravelTravel_Frequently + BusinessTravelTravel_Rarely + GenderFemale + GenderMale + JobRoleHealthcare.Representative + JobRoleLaboratory.Technician + JobRoleManufacturing.Director + JobRoleResearch.Director + JobRoleResearch.Scientist + JobRoleSales.Executive + JobRoleSales.Representative + MaritalStatusMarried + MaritalStatusSingle + OverTimeNo + OverTimeYes ,
                data = HRDevScaledData,
                hidden = c(3,2),
                linear.output = FALSE,
                err.fct = "sse",
                lifesign = "full",
                lifesign.step = 10,
                threshold = 0.01,
                stepmax = 4000)

HRDevScaledData_df = as.data.frame(HRDevScaledData)

HRDevScaledData_df$Prob = as.numeric(nn2$net.result[[1]])

quantile(HRDevScaledData_df$Prob, c(0,10,20,30,40,50,60,70,80,90,100)/100)

hist(HRDevScaledData_df$Prob)


#Basic Confusion Matrix
HRDevScaledData_df$Predicted.Score = ifelse(HRDevScaledData_df$Prob>0.16,1,0)
with(HRDevScaledData_df, table(TargetAttrition,Predicted.Score))

#Detailed Results
confusionMatrix(table(HRDevScaledData_df$Predicted.Score, HRDevScaledData_df$TargetAttrition), dnn = c("Predicted Attrition","Actual Attrition"))

#Scoring Hold-out data using NN
HTargetAttrition = HrHoldOut[,1]
HTargetAttrition
HRHoldOutScaledData =  scale(HrHoldOut[,-1])
HRHoldOutScaledData = cbind(HTargetAttrition,HRHoldOutScaledData )
HoldOutOutput =  compute(nn2,HRHoldOutScaledData[,c("Age","DailyRate","DistanceFromHome","EnvironmentSatisfaction","JobInvolvement","JobLevel","JobSatisfaction","NumCompaniesWorked","RelationshipSatisfaction","StockOptionLevel","TotalWorkingYears","TrainingTimesLastYear","WorkLifeBalance","YearsInCurrentRole","YearsSinceLastPromotion","YearsWithCurrManager","BusinessTravelNon.Travel","BusinessTravelTravel_Frequently","BusinessTravelTravel_Rarely","GenderFemale","GenderMale","JobRoleHealthcare.Representative","JobRoleLaboratory.Technician","JobRoleManufacturing.Director","JobRoleResearch.Director","JobRoleResearch.Scientist","JobRoleSales.Executive","JobRoleSales.Representative","MaritalStatusMarried","MaritalStatusSingle","OverTimeNo","OverTimeYes")])
HRHoldOutScaledData_df = as.data.frame(HRHoldOutScaledData)
HRHoldOutScaledData_df$Prob = HoldOutOutput$net.result[,1]
HRHoldOutScaledData_df$Predicted.Score = ifelse(HRHoldOutScaledData_df$Prob>0.16,1,0) 
cm_HRHOldout = confusionMatrix(table(HRHoldOutScaledData_df$Predicted.Score, HRHoldOutScaledData_df$HTargetAttrition))


names(HRDevScaledData_df)

#Random Forest
rfHRDevScaledData_df = HRDevScaledData_df[,-c(43:45)]
RF <- randomForest(as.factor(TargetAttrition) ~ ., data = rfHRDevScaledData_df[,-1], 
                   ntree=500, mtry = 3, nodesize = 10,
                   importance=TRUE)
print(RF)

#Ploting Random Forest 
plot(RF)
legend("topright", c("OOB", "0", "1"), text.col=1:6, lty=1:3, col=1:3)
title(main="Error Rates Random Forest \n HR data - Development")
RF$err.rate

#Importance of variabels that are used for Random Forest
impVar <- round(randomForest::importance(RF), 2)
impVar[order(impVar[,3], decreasing=TRUE),]

#tuning Random Forest
## Tuning Random Forest
tRF <- tuneRF(x = rfHRDevScaledData_df[,-c(1)], 
              y=as.factor(rfHRDevScaledData_df$TargetAttrition),
              mtryStart = 3, 
              ntreeTry=100, 
              stepFactor = 2, 
              improve = 0.001, 
              trace=TRUE, 
              plot = TRUE,
              doBest = TRUE,
              nodesize = 150, 
              importance=FALSE
)


rfHRDevScaledData_df$predict.class <- predict(tRF, rfHRDevScaledData_df, type="class")
rfHRDevScaledData_df$predict.score <- predict(tRF, rfHRDevScaledData_df, type="prob")
class(rfHRDevScaledData_df$predict.score)


#Evaluating The RF model
pred <- prediction(rfHRDevScaledData_df$predict.score[,2], rfHRDevScaledData_df$TargetAttrition)
perf <- performance(pred, "tpr", "fpr")
plot(perf)
#Kolomorgov- Smirnof test
KS <- max(attr(perf, 'y.values')[[1]]-attr(perf, 'x.values')[[1]])
KS

#Area under Curve
auc <- performance(pred,"auc"); 
auc <- as.numeric(auc@y.values)
auc


## Gini Coefficient
gini = ineq(rfHRDevScaledData_df$predict.score[,2], type="Gini")
gini

## Confusion matrix
confusionMatrix(table(rfHRDevScaledData_df$TargetAttrition,rfHRDevScaledData_df$predict.class))


#Scoring for Hold Out Samples
class(rfHRHoldOutScaledData)
rfHRHoldOutScaledData = as.data.frame(HRHoldOutScaledData)

rfHRHoldOutScaledData$predict.class <- predict(tRF, rfHRHoldOutScaledData[,-1], type="class")
rfHRHoldOutScaledData$predict.score <- predict(tRF, rfHRHoldOutScaledData[,-1], type="prob")


confusionMatrix(rfHRHoldOutScaledData$HTargetAttrition, rfHRHoldOutScaledData$predict.class)



#Ensemble Model of Neural net and RF
#Averaging
#DevData
AverageProb_Ensemble = (HRDevScaledData_df$Prob  + rfHRDevScaledData_df$predict.score[,2])/2
predict.score_Ensemble = ifelse(AverageProb_Ensemble>0.16,1,0)
EnsembleModels = cbind(HRDevScaledData_df$TargetAttrition, 
                      HRDevScaledData_df$Prob,
                      HRDevScaledData_df$Predicted.Score, 
                      rfHRDevScaledData_df$predict.score[,2], 
                      rfHRDevScaledData_df$predict.class, 
                      AverageProb_Ensemble, 
                      predict.score_Ensemble)
EnsembleModels = as.data.frame(EnsembleModels)
names(EnsembleModels) = c("Target",
                          "NeuralNet_prob", 
                          "Neuralnet_Prediected",
                          "RF_Probability",
                          "RF_prediected",
                          "Ensemble_Prob", 
                          "Ensemble_Prediected")
class(EnsembleModels)
str(EnsembleModels)

#Comparison Study
#Ensemble vs Actual
confusionMatrix(EnsembleModels$Target, EnsembleModels$Ensemble_Prediected)
#Accuracy is 91%
